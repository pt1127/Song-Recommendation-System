{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UuXbFf9tHMoM",
        "_bvhQczbHXPZ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# `train_util`"
      ],
      "metadata": {
        "id": "UuXbFf9tHMoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, checkpoint):\n",
        "    \"\"\"Saves model and training parameters at checkpoint + 'last.pth.tar'. If is_best==True, also saves\n",
        "    checkpoint + 'best.pth.tar'\n",
        "    Args:\n",
        "        state: (dict) contains model's state_dict, may contain other keys such as epoch, optimizer state_dict\n",
        "        is_best: (bool) True if it is the best model seen till now\n",
        "        checkpoint: (string) folder where parameters are to be saved\n",
        "    \"\"\"\n",
        "    filepath = os.path.join(checkpoint, 'last.pth.tar')\n",
        "    if not os.path.exists(checkpoint):\n",
        "        print(\"Checkpoint Directory does not exist! Making directory {}\".format(checkpoint))\n",
        "        os.mkdir(checkpoint)\n",
        "    else:\n",
        "        print(\"Checkpoint Directory exists! \")\n",
        "    torch.save(state, filepath)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filepath, os.path.join(checkpoint, 'best.pth.tar'))\n",
        "\n",
        "\n",
        "def save_checkpoint_by_epoch(state, epoch, checkpoint):\n",
        "    \"\"\"Saves model and training parameters at checkpoint + 'last.pth.tar'. If is_best==True, also saves\n",
        "    checkpoint + 'best.pth.tar'\n",
        "    Args:\n",
        "        state: (dict) contains model's state_dict, may contain other keys such as epoch, optimizer state_dict\n",
        "        epoch: (int) epoch no\n",
        "        checkpoint: (string) folder where parameters are to be saved\n",
        "    \"\"\"\n",
        "    filepath = os.path.join(checkpoint, 'model.ep{0}'.format(epoch))\n",
        "    if not os.path.exists(checkpoint):\n",
        "        print(\"Checkpoint Directory does not exist! Making directory {}\".format(checkpoint))\n",
        "        os.mkdir(checkpoint)\n",
        "    else:\n",
        "        print(\"Checkpoint Directory exists! \")\n",
        "    torch.save(state, filepath)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint, model, optimizer=None):\n",
        "    \"\"\"Loads model parameters (state_dict) from file_path. If optimizer is provided, loads state_dict of\n",
        "    optimizer assuming it is present in checkpoint.\n",
        "    Args:\n",
        "        checkpoint: (string) filename which needs to be loaded\n",
        "        model: (torch.nn.Module) model for which the parameters are loaded\n",
        "        optimizer: (torch.optim) optional: resume optimizer from checkpoint\n",
        "    \"\"\"\n",
        "    if not os.path.exists(checkpoint):\n",
        "        raise (\"File doesn't exist {}\".format(checkpoint))\n",
        "    checkpoint = torch.load(checkpoint)\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "    if optimizer:\n",
        "        optimizer.load_state_dict(checkpoint['optim_dict'])\n",
        "\n",
        "    return checkpoint"
      ],
      "metadata": {
        "id": "v38eluH0HKt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `eval_util`"
      ],
      "metadata": {
        "id": "_bvhQczbHXPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def group_labels(labels, preds, group_keys):\n",
        "    \"\"\"Devide labels and preds into several group according to values in group keys.\n",
        "    Args:\n",
        "        labels (list): ground truth label list.\n",
        "        preds (list): prediction score list.\n",
        "        group_keys (list): group key list.\n",
        "    Returns:\n",
        "        all_labels: labels after group.\n",
        "        all_preds: preds after group.\n",
        "    \"\"\"\n",
        "\n",
        "    all_keys = list(set(group_keys))\n",
        "    group_labels = {k: [] for k in all_keys}\n",
        "    group_preds = {k: [] for k in all_keys}\n",
        "\n",
        "    for l, p, k in zip(labels, preds, group_keys):\n",
        "        group_labels[k].append(l)\n",
        "        group_preds[k].append(p)\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    for k in all_keys:\n",
        "        all_labels.append(group_labels[k])\n",
        "        all_preds.append(group_preds[k])\n",
        "\n",
        "    return all_labels, all_preds\n",
        "\n",
        "\n",
        "def mrr_score(y_true, y_score):\n",
        "    \"\"\"Computing mrr score metric.\n",
        "    Args:\n",
        "        y_true (numpy.ndarray): ground-truth labels.\n",
        "        y_score (numpy.ndarray): predicted labels.\n",
        "    Returns:\n",
        "        numpy.ndarray: mrr scores.\n",
        "    \"\"\"\n",
        "    order = np.argsort(y_score)[::-1]\n",
        "    y_true = np.take(y_true, order)\n",
        "    rr_score = y_true / (np.arange(len(y_true)) + 1)\n",
        "    return np.sum(rr_score) / np.sum(y_true)\n",
        "\n",
        "\n",
        "def ndcg_score(y_true, y_score, k=10):\n",
        "    \"\"\"Computing ndcg score metric at k.\n",
        "    Args:\n",
        "        y_true (numpy.ndarray): ground-truth labels.\n",
        "        y_score (numpy.ndarray): predicted labels.\n",
        "    Returns:\n",
        "        numpy.ndarray: ndcg scores.\n",
        "    \"\"\"\n",
        "    best = dcg_score(y_true, y_true, k)\n",
        "    actual = dcg_score(y_true, y_score, k)\n",
        "    return actual / best\n",
        "\n",
        "\n",
        "def dcg_score(y_true, y_score, k=10):\n",
        "    \"\"\"Computing dcg score metric at k.\n",
        "    Args:\n",
        "        y_true (numpy.ndarray): ground-truth labels.\n",
        "        y_score (numpy.ndarray): predicted labels.\n",
        "    Returns:\n",
        "        numpy.ndarray: dcg scores.\n",
        "    \"\"\"\n",
        "    k = min(np.shape(y_true)[-1], k)\n",
        "    order = np.argsort(y_score)[::-1]\n",
        "    y_true = np.take(y_true, order[:k])\n",
        "    gains = 2 ** y_true - 1\n",
        "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
        "    return np.sum(gains / discounts)\n",
        "\n",
        "\n",
        "def cal_metric(labels, preds, metrics):\n",
        "    \"\"\"Calculate metrics,such as auc, logloss.\n",
        "    FIXME:\n",
        "        refactor this with the reco metrics and make it explicit.\n",
        "    \"\"\"\n",
        "    res = {}\n",
        "    for metric in metrics:\n",
        "        if metric == \"auc\":\n",
        "            tmp_labels, tmp_preds = [], []\n",
        "            for l, p in zip(labels, preds):\n",
        "                tmp_labels += l\n",
        "                tmp_preds += p\n",
        "            auc = roc_auc_score(np.asarray(tmp_labels), np.asarray(tmp_preds))\n",
        "            res[\"auc\"] = round(auc, 4)\n",
        "        elif metric == \"mean_mrr\":\n",
        "            mean_mrr = np.mean(\n",
        "                [\n",
        "                    mrr_score(each_labels, each_preds)\n",
        "                    for each_labels, each_preds in zip(labels, preds)\n",
        "                ]\n",
        "            )\n",
        "            res[\"mean_mrr\"] = round(mean_mrr, 4)\n",
        "        elif metric.startswith(\"ndcg\"):  # format like:  ndcg@2;4;6;8\n",
        "            ndcg_list = [1, 2]\n",
        "            ks = metric.split(\"@\")\n",
        "            if len(ks) > 1:\n",
        "                ndcg_list = [int(token) for token in ks[1].split(\";\")]\n",
        "            for k in ndcg_list:\n",
        "                ndcg_temp = np.mean(\n",
        "                    [\n",
        "                        ndcg_score(each_labels, each_preds, k)\n",
        "                        for each_labels, each_preds in zip(labels, preds)\n",
        "                    ]\n",
        "                )\n",
        "                res[\"ndcg@{0}\".format(k)] = round(ndcg_temp, 4)\n",
        "        elif metric == \"group_auc\":\n",
        "            auc_list = []\n",
        "            for each_labels, each_preds in zip(labels, preds):\n",
        "                try:\n",
        "                    x = roc_auc_score(each_labels, each_preds)\n",
        "                    auc_list.append(x)\n",
        "                except:\n",
        "                    print(\"There are only zero labels\")\n",
        "                    auc_list.append(0.0)\n",
        "            group_auc = np.mean(\n",
        "                auc_list\n",
        "            )\n",
        "            res[\"group_auc\"] = round(group_auc, 4)\n",
        "        else:\n",
        "            raise ValueError(\"not define this metric {0}\".format(metric))\n",
        "    return res"
      ],
      "metadata": {
        "id": "aXOqpUhsHZzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `gather`"
      ],
      "metadata": {
        "id": "xobUW7q5HcFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import scipy.stats as ss\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "def gather(output_path, input_file, flag, validate=False, save=True): ## ('result/', validate=True, save=False)\n",
        "    preds = []\n",
        "    labels = []\n",
        "    imp_indexes = []\n",
        "\n",
        "  \n",
        "    with open(output_path + input_file, 'r', encoding='utf-8') as f:\n",
        "        cur_result = json.load(f)\n",
        "    imp_indexes += cur_result['imp']\n",
        "    labels += cur_result['labels']\n",
        "\n",
        "    preds += cur_result['preds']\n",
        "    all_keys = list(set(imp_indexes))\n",
        "    group_labels = {k: [] for k in all_keys}\n",
        "    group_preds = {k: [] for k in all_keys}\n",
        "\n",
        "    for l, p, k in zip(labels, preds, imp_indexes):\n",
        "        group_labels[k].append(l)\n",
        "        group_preds[k].append(p)\n",
        "    \n",
        "    if validate:\n",
        "        all_labels = []\n",
        "        all_preds = []\n",
        "        for k in all_keys:\n",
        "            all_labels.append(group_labels[k])\n",
        "            all_preds.append(group_preds[k])\n",
        "        \n",
        "        metric_list = [x.strip() for x in \"group_auc || mean_mrr || ndcg@5;10\".split(\"||\")]\n",
        "        ret = cal_metric(all_labels, all_preds, metric_list)\n",
        "        for metric, val in ret.items():\n",
        "            print(\"Eval - {}: {}\".format(metric, val))\n",
        "\n",
        "    if save:\n",
        "        final_arr = []\n",
        "        for k in group_preds.keys():\n",
        "            new_row = []\n",
        "            new_row.append(k)\n",
        "            new_row.append(','.join(list(map(str, np.array(group_labels[k]).astype(int)))))\n",
        "            new_row.append(','.join(list(map(str, np.array(group_preds[k]).astype(float)))))\n",
        "            \n",
        "            rank = ss.rankdata(-np.array(group_preds[k])).astype(int).tolist()\n",
        "            new_row.append('[' + ','.join(list(map(str, rank))) + ']')\n",
        "            \n",
        "            assert(len(rank) == len(group_labels[k]))\n",
        "            \n",
        "            final_arr.append(new_row)\n",
        "        \n",
        "        fdf = pd.DataFrame(final_arr, columns=['impression', 'labels', 'preds', 'ranks'])\n",
        "        fdf.drop(columns=['labels', 'ranks']).to_csv(output_path + 'score-{}.txt'.format(flag), sep=' ', index=False)\n",
        "        fdf.drop(columns=['labels', 'preds']).to_csv(output_path + 'result-{}.txt'.format(flag), header=None, sep=' ', index=False)"
      ],
      "metadata": {
        "id": "XvjsX4ZvHeRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `config`"
      ],
      "metadata": {
        "id": "nKBwbGXeiglQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "class ModelConfig():\n",
        "    def __init__(self, root):\n",
        "\n",
        "        tracks_dict = json.load(open('{}/tracks_dict.jsonl'.format(root), 'r', encoding='utf-8'))\n",
        "        self.tracks_num = len(tracks_dict)\n",
        "        self.word_emb = np.load('{}/emb.npy'.format(root))\n",
        "        self.word_num = len(self.word_emb)\n",
        "\n",
        "        self.pos_hist_length = 30\n",
        "        self.max_lyric_len = 100\n",
        "        self.neg_count = 4\n",
        "        self.word_dim = 300\n",
        "        self.hidden_size = 300\n",
        "        self.head_num = 6\n",
        "        self.dropout = 0.2\n",
        "        \n",
        "        return None"
      ],
      "metadata": {
        "id": "fFhWGkvVii2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `modules`"
      ],
      "metadata": {
        "id": "uxWsJIqlij86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class SelfAttend(nn.Module):\n",
        "    def __init__(self, embedding_size: int) -> None:\n",
        "        super(SelfAttend, self).__init__()\n",
        "\n",
        "        self.h1 = nn.Sequential(\n",
        "            nn.Linear(embedding_size, 200),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        \n",
        "        self.gate_layer = nn.Linear(200, 1)\n",
        "\n",
        "    def forward(self, seqs, seq_masks=None):\n",
        "        \"\"\"\n",
        "        :param seqs: shape [batch_size, seq_length, embedding_size]\n",
        "        :param seq_lens: shape [batch_size, seq_length]\n",
        "        :return: shape [batch_size, seq_length, embedding_size]\n",
        "        \"\"\"\n",
        "        gates = self.gate_layer(self.h1(seqs)).squeeze(-1)\n",
        "        if seq_masks is not None:\n",
        "            gates = gates.masked_fill(seq_masks == 0, -1e9)\n",
        "        p_attn = F.softmax(gates, dim=-1)\n",
        "        p_attn = p_attn.unsqueeze(-1)\n",
        "        h = seqs * p_attn\n",
        "        output = torch.sum(h, dim=1)\n",
        "        return output\n",
        "\n",
        "class TitleEncoder(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super(TitleEncoder, self).__init__()\n",
        "        self.cfg = cfg\n",
        "        self.word_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(cfg.word_emb), freeze=False)\n",
        "\n",
        "        self.mh_self_attn = nn.MultiheadAttention(\n",
        "            cfg.hidden_size, num_heads=cfg.head_num\n",
        "        )\n",
        "        self.word_self_attend = SelfAttend(cfg.hidden_size)\n",
        "\n",
        "        self.user_mh_self_attn = nn.MultiheadAttention(\n",
        "            cfg.hidden_size, num_heads=cfg.head_num\n",
        "        )\n",
        "        self.pos_self_attend = SelfAttend(cfg.hidden_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(cfg.dropout)\n",
        "        self.word_layer_norm = nn.LayerNorm(cfg.hidden_size)\n",
        "        self.user_layer_norm = nn.LayerNorm(cfg.hidden_size)\n",
        "\n",
        "    def _extract_hidden_rep(self, seqs):\n",
        "        \"\"\"\n",
        "        Encoding\n",
        "        :param seqs: [*, seq_length]\n",
        "        :param seq_lens: [*]\n",
        "        :return: Tuple, (1) [*, seq_length, hidden_size] (2) [*, seq_length];\n",
        "        \"\"\"\n",
        "        embs = self.word_embedding(seqs)\n",
        "        X = self.dropout(embs)\n",
        "\n",
        "        X = X.permute(1, 0, 2)\n",
        "        output, _ = self.mh_self_attn(X, X, X)\n",
        "        output = output.permute(1, 0, 2)\n",
        "        output = self.dropout(output)\n",
        "        X = X.permute(1, 0, 2)\n",
        "\n",
        "        return self.word_layer_norm(output + X)\n",
        "\n",
        "    def encode_news(self, seqs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            seqs: [*, max_news_len]\n",
        "            seq_lens: [*]\n",
        "        Returns:\n",
        "            [*, hidden_size]\n",
        "        \"\"\"\n",
        "        hiddens = self._extract_hidden_rep(seqs)\n",
        "\n",
        "        # [*, hidden_size]\n",
        "        self_attend = self.word_self_attend(hiddens)\n",
        "\n",
        "        return self_attend\n",
        "\n",
        "    def encode_user(self, seqs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            seqs: [*, max_hist_len, hidden_size]\n",
        "        Returns:\n",
        "            [*, hidden_size]\n",
        "        \"\"\"\n",
        "        user_mh_self_attn = self.user_mh_self_attn\n",
        "        news_self_attend = self.pos_self_attend\n",
        "\n",
        "        hiddens = seqs.permute(1, 0, 2)\n",
        "        user_hiddens, _ = user_mh_self_attn(hiddens, hiddens, hiddens)\n",
        "        user_hiddens = user_hiddens.permute(1, 0, 2)\n",
        "\n",
        "        residual_sum = self.user_layer_norm(user_hiddens + seqs)\n",
        "        user_title_hidden = news_self_attend(residual_sum)\n",
        "\n",
        "        return user_title_hidden\n",
        "\n",
        "\n",
        "class NodesEncoder(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super(NodesEncoder, self).__init__()\n",
        "        self.cfg = cfg\n",
        "        \n",
        "        self.user_mh_self_attn = nn.MultiheadAttention(\n",
        "            cfg.hidden_size, num_heads=cfg.head_num)\n",
        "        \n",
        "        self.nodes_mh_self_attn = nn.MultiheadAttention(\n",
        "            cfg.hidden_size, num_heads=cfg.head_num)\n",
        "        \n",
        "        self.pos_self_attend = SelfAttend(cfg.hidden_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(cfg.dropout)\n",
        "        self.user_layer_norm = nn.LayerNorm(cfg.hidden_size)\n",
        "\n",
        "    def forward(self, pos): ## neg, pos_nodes, neg_nodes\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            seqs: [*, max_hist_len, hidden_size]\n",
        "        Returns:\n",
        "            [*, hidden_size]\n",
        "        \"\"\"\n",
        "\n",
        "        pos_permuted = pos.permute(1, 0, 2)\n",
        "        pos_hiddens, _ = self.user_mh_self_attn(pos_permuted, pos_permuted, pos_permuted)\n",
        "        pos_hiddens = pos_hiddens.permute(1, 0, 2)\n",
        "        pos_residual = self.user_layer_norm(pos_hiddens + pos)\n",
        "\n",
        "        pos_s = self.pos_self_attend(pos_residual)\n",
        "\n",
        "\n",
        "        return pos_s ## pos_s, pos_s_nodes, neg_s, neg_s_nodes, pos_c, pos_c_nodes, neg_c, neg_c_nodes\n",
        "\n",
        "class MaskedSelfAttend(nn.Module):\n",
        "    def __init__(self, hidden_size, mask_len) -> None:\n",
        "        super(MaskedSelfAttend, self).__init__()\n",
        "\n",
        "        # self.query = nn.Linear(cfg.hidden_size, cfg.hidden_size)\n",
        "        # self.key = nn.Linear(cfg.hidden_size, cfg.hidden_size)\n",
        "        # self.value = nn.Linear(cfg.hidden_size, cfg.hidden_size)\n",
        "        self.mask = nn.Parameter(torch.eye(mask_len) == 1, requires_grad=False)\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    def forward(self, q):\n",
        "        # q (batch_size, seq_len, hidden_size)\n",
        "        \n",
        "        k = q.permute(0, 2, 1)\n",
        "        sim = torch.matmul(q, k) / math.sqrt(self.hidden_size)\n",
        "        sim = torch.softmax(sim.masked_fill_(self.mask, -1e9), dim=-1)\n",
        "        output = torch.matmul(sim, q)\n",
        "\n",
        "        return output\n",
        "\n",
        "class Multihead_bandti(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "\n",
        "        super(Multihead_bandti, self).__init__()\n",
        "\n",
        "        self.head_num = cfg.head_num\n",
        "        self.head_dim = cfg.hidden_size // cfg.head_num\n",
        "        self.hidden_size = cfg.hidden_size\n",
        "        \n",
        "        self.policy_1 = nn.Sequential(\n",
        "            nn.Linear(cfg.hidden_size * 2, cfg.hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(cfg.hidden_size, self.head_num))\n",
        "\n",
        "    \n",
        "    def forward(self, refer, s1, s2, s3, s4):\n",
        "\n",
        "        gamma_1 = self.policy_1(refer).unsqueeze(-1)\n",
        "\n",
        "        s1 = s1.view(-1, refer.size(1), self.head_num, self.head_dim)\n",
        "        final = gamma_1 * s1\n",
        "        final = final.reshape(-1, refer.size(1), self.hidden_size)\n",
        "\n",
        "        return final"
      ],
      "metadata": {
        "id": "-9cbqoYok0fT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `pnrec`"
      ],
      "metadata": {
        "id": "squ2WAfblnv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class PNRec(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super(PNRec, self).__init__()\n",
        "\n",
        "        self.title_encoder = TitleEncoder(cfg)\n",
        "        self.news_encoder = NodesEncoder(cfg)\n",
        "        self.cfg = cfg\n",
        "        self.policy_pos_s = nn.Sequential(\n",
        "            nn.Linear(cfg.hidden_size * 2, cfg.hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(cfg.hidden_size, 1),)\n",
        " \n",
        "\n",
        "        self.news_embedding = nn.Embedding(cfg.tracks_num, cfg.hidden_size)\n",
        "\n",
        "        self.title_self_attend = SelfAttend(cfg.hidden_size)\n",
        "\n",
        "    def forward(self, data, test_mode=False):\n",
        "        neg_num = self.cfg.neg_count\n",
        "        if test_mode:\n",
        "            neg_num = 0\n",
        "\n",
        "        target_news = data[3].reshape(-1, self.cfg.max_lyric_len)\n",
        "        target_news = self.title_encoder.encode_news(target_news).reshape(-1, neg_num + 1, self.cfg.hidden_size)\n",
        "        target_all = target_news\n",
        "\n",
        "        pos_his = data[4].reshape(-1, self.cfg.max_lyric_len)\n",
        "        pos_his = self.title_encoder.encode_news(pos_his).reshape(-1, self.cfg.pos_hist_length, self.cfg.hidden_size)\n",
        "\n",
        "        title_v = self.title_self_attend(pos_his)\n",
        "        title_v = title_v.repeat(1, neg_num + 1).view(-1, neg_num + 1, self.cfg.hidden_size)\n",
        "        \n",
        "        pos_s= self.news_encoder(pos_his)\n",
        "\n",
        "        pos_s = pos_s.repeat(1, neg_num + 1).view(-1, neg_num + 1, self.cfg.hidden_size)\n",
        "     \n",
        "        news_states = torch.cat([title_v, target_news], dim=-1)\n",
        "        gamma_1 = self.policy_pos_s(news_states)\n",
        "        news_final = gamma_1 * pos_s\n",
        "\n",
        "        ###return torch.sum(torch.cat([news_final, node_final], dim=-1) * target_all, dim=-1)\n",
        "        return torch.sum(news_final * target_all, dim=-1)"
      ],
      "metadata": {
        "id": "tIsWDpL_lvGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `validate`"
      ],
      "metadata": {
        "id": "3DS61EpZECVy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97z4PX79Xlb9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import argparse\n",
        "import json\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.distributed as dist\n",
        "import torch.nn.functional as F\n",
        "import logging\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "import math\n",
        "\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "def run(dev_dataset, epoch):\n",
        "    filenum=20\n",
        "    batch_size=128\n",
        "    root=\"data\"\n",
        "    start_dev=2\n",
        "    result_path = 'result/test/'\n",
        "    saved_model_path = 'checkpoint/model.ep{}'.format(epoch)\n",
        "\n",
        "    model_cfg = ModelConfig(root)\n",
        "    model = PNRec(model_cfg)\n",
        "\n",
        "    pretrained_model = torch.load(saved_model_path)\n",
        "\n",
        "    model.load_state_dict(pretrained_model['model_state_dict'], strict=False)\n",
        "    model.eval()\n",
        "    \n",
        "    valid_data_loader = DataLoader(dev_dataset, shuffle=False)\n",
        "\n",
        "    data_iter = tqdm(enumerate(valid_data_loader),\n",
        "                        desc=\"epoch_dev %d\" % epoch,\n",
        "                        total=len(valid_data_loader),\n",
        "                        bar_format=\"{l_bar}{r_bar}\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds, truths, imp_ids = list(), list(), list()\n",
        "        for i, data in data_iter:\n",
        "\n",
        "            imp_ids += data[0].numpy().tolist()\n",
        "            truths += data[1].numpy().tolist()\n",
        "\n",
        "            pred = model(data, test_mode=True)\n",
        "            if pred.dim() > 1:\n",
        "                pred = pred.squeeze()\n",
        "            try:\n",
        "                preds += pred.numpy().tolist()\n",
        "            except:\n",
        "                preds.append(int(pred.numpy()))\n",
        "\n",
        "        tmp_dict = {}\n",
        "        tmp_dict['imp'] = imp_ids\n",
        "        tmp_dict['labels'] = truths\n",
        "        tmp_dict['preds'] = preds\n",
        "\n",
        "        with open(result_path + 'tmp_test-{}.json'.format(epoch), 'w+', encoding='utf-8') as f:\n",
        "            json.dump(tmp_dict, f)\n",
        "\n",
        "    gather(result_path, 'tmp_test-{}.json'.format(epoch), epoch, validate=True, save=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***RUN***"
      ],
      "metadata": {
        "id": "_xKKOs8nteju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yZX7zY0Rtq9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fee6e3b2-4e54-4309-a797-366a5bc5bd1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/Những năm tháng Đại học/[4] DS300.N11 - Hệ khuyến nghị/ReSys_/DRPN'"
      ],
      "metadata": {
        "id": "MHn5UlHctxFv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0323219b-c0c6-4b1b-f668-4a5b136e48b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/127eMhUqzE2w-Fg1IDb9eLKYQHPsZSeG2/Những năm tháng Đại học/[4] DS300.N11 - Hệ khuyến nghị/ReSys_/DRPN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = torch.load('data/test/test.pt')\n",
        "for i in range(5):\n",
        "  save_model_path = 'checkpoint/model.ep{}'.format(i)\n",
        "  run(test, i)\n",
        "  "
      ],
      "metadata": {
        "id": "d9QsHUAQtg7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acbaca93-5375-4be0-8e6f-105e42784d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch_dev 0: 100%|| 13477/13477 [19:59<00:00, 11.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval - group_auc: 0.8899\n",
            "Eval - mean_mrr: 0.2227\n",
            "Eval - ndcg@5: 0.9068\n",
            "Eval - ndcg@10: 0.9015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch_dev 1: 100%|| 13477/13477 [20:03<00:00, 11.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval - group_auc: 0.9187\n",
            "Eval - mean_mrr: 0.2312\n",
            "Eval - ndcg@5: 0.9431\n",
            "Eval - ndcg@10: 0.934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch_dev 2: 100%|| 13477/13477 [20:00<00:00, 11.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval - group_auc: 0.9313\n",
            "Eval - mean_mrr: 0.2336\n",
            "Eval - ndcg@5: 0.9475\n",
            "Eval - ndcg@10: 0.9436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch_dev 3: 100%|| 13477/13477 [20:12<00:00, 11.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval - group_auc: 0.9334\n",
            "Eval - mean_mrr: 0.234\n",
            "Eval - ndcg@5: 0.9489\n",
            "Eval - ndcg@10: 0.9432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch_dev 4: 100%|| 13477/13477 [20:03<00:00, 11.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval - group_auc: 0.9381\n",
            "Eval - mean_mrr: 0.237\n",
            "Eval - ndcg@5: 0.9579\n",
            "Eval - ndcg@10: 0.9521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_model_path = 'checkpoint/model.ep{}'.format(1)\n",
        "run(test, i)"
      ],
      "metadata": {
        "id": "i1R_EHWj8gXY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}