{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["UuXbFf9tHMoM","_bvhQczbHXPZ"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# `train_util`"],"metadata":{"id":"UuXbFf9tHMoM"}},{"cell_type":"code","source":["import os\n","import json\n","import random\n","\n","import torch\n","import numpy as np\n","\n","\n","def save_checkpoint(state, is_best, checkpoint):\n","    \"\"\"Saves model and training parameters at checkpoint + 'last.pth.tar'. If is_best==True, also saves\n","    checkpoint + 'best.pth.tar'\n","    Args:\n","        state: (dict) contains model's state_dict, may contain other keys such as epoch, optimizer state_dict\n","        is_best: (bool) True if it is the best model seen till now\n","        checkpoint: (string) folder where parameters are to be saved\n","    \"\"\"\n","    filepath = os.path.join(checkpoint, 'last.pth.tar')\n","    if not os.path.exists(checkpoint):\n","        print(\"Checkpoint Directory does not exist! Making directory {}\".format(checkpoint))\n","        os.mkdir(checkpoint)\n","    else:\n","        print(\"Checkpoint Directory exists! \")\n","    torch.save(state, filepath)\n","    if is_best:\n","        shutil.copyfile(filepath, os.path.join(checkpoint, 'best.pth.tar'))\n","\n","\n","def save_checkpoint_by_epoch(state, epoch, checkpoint):\n","    \"\"\"Saves model and training parameters at checkpoint + 'last.pth.tar'. If is_best==True, also saves\n","    checkpoint + 'best.pth.tar'\n","    Args:\n","        state: (dict) contains model's state_dict, may contain other keys such as epoch, optimizer state_dict\n","        epoch: (int) epoch no\n","        checkpoint: (string) folder where parameters are to be saved\n","    \"\"\"\n","    filepath = os.path.join(checkpoint, 'model.ep{0}'.format(epoch))\n","    if not os.path.exists(checkpoint):\n","        print(\"Checkpoint Directory does not exist! Making directory {}\".format(checkpoint))\n","        os.mkdir(checkpoint)\n","    else:\n","        print(\"Checkpoint Directory exists! \")\n","    torch.save(state, filepath)\n","\n","\n","def load_checkpoint(checkpoint, model, optimizer=None):\n","    \"\"\"Loads model parameters (state_dict) from file_path. If optimizer is provided, loads state_dict of\n","    optimizer assuming it is present in checkpoint.\n","    Args:\n","        checkpoint: (string) filename which needs to be loaded\n","        model: (torch.nn.Module) model for which the parameters are loaded\n","        optimizer: (torch.optim) optional: resume optimizer from checkpoint\n","    \"\"\"\n","    if not os.path.exists(checkpoint):\n","        raise (\"File doesn't exist {}\".format(checkpoint))\n","    checkpoint = torch.load(checkpoint)\n","    model.load_state_dict(checkpoint['state_dict'])\n","\n","    if optimizer:\n","        optimizer.load_state_dict(checkpoint['optim_dict'])\n","\n","    return checkpoint"],"metadata":{"id":"v38eluH0HKt4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# `eval_util`"],"metadata":{"id":"_bvhQczbHXPZ"}},{"cell_type":"code","source":["from sklearn.metrics import (\n","    roc_auc_score,\n",")\n","import numpy as np\n","\n","\n","def group_labels(labels, preds, group_keys):\n","    \"\"\"Devide labels and preds into several group according to values in group keys.\n","    Args:\n","        labels (list): ground truth label list.\n","        preds (list): prediction score list.\n","        group_keys (list): group key list.\n","    Returns:\n","        all_labels: labels after group.\n","        all_preds: preds after group.\n","    \"\"\"\n","\n","    all_keys = list(set(group_keys))\n","    group_labels = {k: [] for k in all_keys}\n","    group_preds = {k: [] for k in all_keys}\n","\n","    for l, p, k in zip(labels, preds, group_keys):\n","        group_labels[k].append(l)\n","        group_preds[k].append(p)\n","\n","    all_labels = []\n","    all_preds = []\n","    for k in all_keys:\n","        all_labels.append(group_labels[k])\n","        all_preds.append(group_preds[k])\n","\n","    return all_labels, all_preds\n","\n","\n","def mrr_score(y_true, y_score):\n","    \"\"\"Computing mrr score metric.\n","    Args:\n","        y_true (numpy.ndarray): ground-truth labels.\n","        y_score (numpy.ndarray): predicted labels.\n","    Returns:\n","        numpy.ndarray: mrr scores.\n","    \"\"\"\n","    order = np.argsort(y_score)[::-1]\n","    y_true = np.take(y_true, order)\n","    rr_score = y_true / (np.arange(len(y_true)) + 1)\n","    return np.sum(rr_score) / np.sum(y_true)\n","\n","\n","def ndcg_score(y_true, y_score, k=10):\n","    \"\"\"Computing ndcg score metric at k.\n","    Args:\n","        y_true (numpy.ndarray): ground-truth labels.\n","        y_score (numpy.ndarray): predicted labels.\n","    Returns:\n","        numpy.ndarray: ndcg scores.\n","    \"\"\"\n","    best = dcg_score(y_true, y_true, k)\n","    actual = dcg_score(y_true, y_score, k)\n","    return actual / best\n","\n","\n","def dcg_score(y_true, y_score, k=10):\n","    \"\"\"Computing dcg score metric at k.\n","    Args:\n","        y_true (numpy.ndarray): ground-truth labels.\n","        y_score (numpy.ndarray): predicted labels.\n","    Returns:\n","        numpy.ndarray: dcg scores.\n","    \"\"\"\n","    k = min(np.shape(y_true)[-1], k)\n","    order = np.argsort(y_score)[::-1]\n","    y_true = np.take(y_true, order[:k])\n","    gains = 2 ** y_true - 1\n","    discounts = np.log2(np.arange(len(y_true)) + 2)\n","    return np.sum(gains / discounts)\n","\n","\n","def cal_metric(labels, preds, metrics):\n","    \"\"\"Calculate metrics,such as auc, logloss.\n","    FIXME:\n","        refactor this with the reco metrics and make it explicit.\n","    \"\"\"\n","    res = {}\n","    for metric in metrics:\n","        if metric == \"auc\":\n","            tmp_labels, tmp_preds = [], []\n","            for l, p in zip(labels, preds):\n","                tmp_labels += l\n","                tmp_preds += p\n","            auc = roc_auc_score(np.asarray(tmp_labels), np.asarray(tmp_preds))\n","            res[\"auc\"] = round(auc, 4)\n","        elif metric == \"mean_mrr\":\n","            mean_mrr = np.mean(\n","                [\n","                    mrr_score(each_labels, each_preds)\n","                    for each_labels, each_preds in zip(labels, preds)\n","                ]\n","            )\n","            res[\"mean_mrr\"] = round(mean_mrr, 4)\n","        elif metric.startswith(\"ndcg\"):  # format like:  ndcg@2;4;6;8\n","            ndcg_list = [1, 2]\n","            ks = metric.split(\"@\")\n","            if len(ks) > 1:\n","                ndcg_list = [int(token) for token in ks[1].split(\";\")]\n","            for k in ndcg_list:\n","                ndcg_temp = np.mean(\n","                    [\n","                        ndcg_score(each_labels, each_preds, k)\n","                        for each_labels, each_preds in zip(labels, preds)\n","                    ]\n","                )\n","                res[\"ndcg@{0}\".format(k)] = round(ndcg_temp, 4)\n","        elif metric == \"group_auc\":\n","            auc_list = []\n","            for each_labels, each_preds in zip(labels, preds):\n","                try:\n","                    x = roc_auc_score(each_labels, each_preds)\n","                    auc_list.append(x)\n","                except:\n","                    print(\"There are only zero labels\")\n","                    auc_list.append(0.0)\n","            group_auc = np.mean(\n","                auc_list\n","            )\n","            res[\"group_auc\"] = round(group_auc, 4)\n","        else:\n","            raise ValueError(\"not define this metric {0}\".format(metric))\n","    return res"],"metadata":{"id":"aXOqpUhsHZzU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# `gather`"],"metadata":{"id":"xobUW7q5HcFs"}},{"cell_type":"code","source":["import os\n","import argparse\n","from tqdm import tqdm\n","import json\n","import scipy.stats as ss\n","import numpy as np\n","import pandas as pd\n","import math\n","import torch\n","\n","\n","\n","def gather(output_path, input_file, flag, validate=False, save=True): ## ('result/', validate=True, save=False)\n","    preds = []\n","    labels = []\n","    imp_indexes = []\n","\n","  \n","    with open(output_path + input_file, 'r', encoding='utf-8') as f:\n","        cur_result = json.load(f)\n","    imp_indexes += cur_result['imp']\n","    labels += cur_result['labels']\n","\n","    preds += cur_result['preds']\n","    all_keys = list(set(imp_indexes))\n","    group_labels = {k: [] for k in all_keys}\n","    group_preds = {k: [] for k in all_keys}\n","\n","    for l, p, k in zip(labels, preds, imp_indexes):\n","        group_labels[k].append(l)\n","        group_preds[k].append(p)\n","    \n","    if validate:\n","        all_labels = []\n","        all_preds = []\n","        for k in all_keys:\n","            all_labels.append(group_labels[k])\n","            all_preds.append(group_preds[k])\n","        \n","        metric_list = [x.strip() for x in \"group_auc || mean_mrr || ndcg@5;10\".split(\"||\")]\n","        ret = cal_metric(all_labels, all_preds, metric_list)\n","        for metric, val in ret.items():\n","            print(\"Eval - {}: {}\".format(metric, val))\n","\n","    if save:\n","        final_arr = []\n","        for k in group_preds.keys():\n","            new_row = []\n","            new_row.append(k)\n","            new_row.append(','.join(list(map(str, np.array(group_labels[k]).astype(int)))))\n","            new_row.append(','.join(list(map(str, np.array(group_preds[k]).astype(float)))))\n","            \n","            rank = ss.rankdata(-np.array(group_preds[k])).astype(int).tolist()\n","            new_row.append('[' + ','.join(list(map(str, rank))) + ']')\n","            \n","            assert(len(rank) == len(group_labels[k]))\n","            \n","            final_arr.append(new_row)\n","        \n","        fdf = pd.DataFrame(final_arr, columns=['impression', 'labels', 'preds', 'ranks'])\n","        fdf.drop(columns=['labels', 'ranks']).to_csv(output_path + 'score-{}.txt'.format(flag), sep=' ', index=False)\n","        fdf.drop(columns=['labels', 'preds']).to_csv(output_path + 'result-{}.txt'.format(flag), header=None, sep=' ', index=False)"],"metadata":{"id":"XvjsX4ZvHeRz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# `config`"],"metadata":{"id":"nKBwbGXeiglQ"}},{"cell_type":"code","source":["import json\n","import pickle\n","import numpy as np\n","\n","class ModelConfig():\n","    def __init__(self, root):\n","\n","        tracks_dict = json.load(open('{}/tracks_dict.jsonl'.format(root), 'r', encoding='utf-8'))\n","        self.tracks_num = len(tracks_dict)\n","        self.word_emb = np.load('{}/emb.npy'.format(root))\n","        self.word_num = len(self.word_emb)\n","\n","        self.pos_hist_length = 30\n","        self.max_lyric_len = 100\n","        self.neg_count = 4\n","        self.word_dim = 300\n","        self.hidden_size = 300\n","        self.head_num = 6\n","        self.dropout = 0.2\n","        \n","        return None"],"metadata":{"id":"fFhWGkvVii2H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# `modules`"],"metadata":{"id":"uxWsJIqlij86"}},{"cell_type":"code","source":["import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class SelfAttend(nn.Module):\n","    def __init__(self, embedding_size: int) -> None:\n","        super(SelfAttend, self).__init__()\n","\n","        self.h1 = nn.Sequential(\n","            nn.Linear(embedding_size, 200),\n","            nn.Tanh()\n","        )\n","        \n","        self.gate_layer = nn.Linear(200, 1)\n","\n","    def forward(self, seqs, seq_masks=None):\n","        \"\"\"\n","        :param seqs: shape [batch_size, seq_length, embedding_size]\n","        :param seq_lens: shape [batch_size, seq_length]\n","        :return: shape [batch_size, seq_length, embedding_size]\n","        \"\"\"\n","        gates = self.gate_layer(self.h1(seqs)).squeeze(-1)\n","        if seq_masks is not None:\n","            gates = gates.masked_fill(seq_masks == 0, -1e9)\n","        p_attn = F.softmax(gates, dim=-1)\n","        p_attn = p_attn.unsqueeze(-1)\n","        h = seqs * p_attn\n","        output = torch.sum(h, dim=1)\n","        return output\n","\n","class TitleEncoder(nn.Module):\n","    def __init__(self, cfg):\n","        super(TitleEncoder, self).__init__()\n","        self.cfg = cfg\n","        self.word_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(cfg.word_emb), freeze=False)\n","\n","        self.mh_self_attn = nn.MultiheadAttention(\n","            cfg.hidden_size, num_heads=cfg.head_num\n","        )\n","        self.word_self_attend = SelfAttend(cfg.hidden_size)\n","\n","        self.user_mh_self_attn = nn.MultiheadAttention(\n","            cfg.hidden_size, num_heads=cfg.head_num\n","        )\n","        self.pos_self_attend = SelfAttend(cfg.hidden_size)\n","\n","        self.dropout = nn.Dropout(cfg.dropout)\n","        self.word_layer_norm = nn.LayerNorm(cfg.hidden_size)\n","        self.user_layer_norm = nn.LayerNorm(cfg.hidden_size)\n","\n","    def _extract_hidden_rep(self, seqs):\n","        \"\"\"\n","        Encoding\n","        :param seqs: [*, seq_length]\n","        :param seq_lens: [*]\n","        :return: Tuple, (1) [*, seq_length, hidden_size] (2) [*, seq_length];\n","        \"\"\"\n","        embs = self.word_embedding(seqs)\n","        X = self.dropout(embs)\n","\n","        X = X.permute(1, 0, 2)\n","        output, _ = self.mh_self_attn(X, X, X)\n","        output = output.permute(1, 0, 2)\n","        output = self.dropout(output)\n","        X = X.permute(1, 0, 2)\n","\n","        return self.word_layer_norm(output + X)\n","\n","    def encode_news(self, seqs):\n","        \"\"\"\n","        Args:\n","            seqs: [*, max_news_len]\n","            seq_lens: [*]\n","        Returns:\n","            [*, hidden_size]\n","        \"\"\"\n","        hiddens = self._extract_hidden_rep(seqs)\n","\n","        # [*, hidden_size]\n","        self_attend = self.word_self_attend(hiddens)\n","\n","        return self_attend\n","\n","    def encode_user(self, seqs):\n","        \"\"\"\n","        Args:\n","            seqs: [*, max_hist_len, hidden_size]\n","        Returns:\n","            [*, hidden_size]\n","        \"\"\"\n","        user_mh_self_attn = self.user_mh_self_attn\n","        news_self_attend = self.pos_self_attend\n","\n","        hiddens = seqs.permute(1, 0, 2)\n","        user_hiddens, _ = user_mh_self_attn(hiddens, hiddens, hiddens)\n","        user_hiddens = user_hiddens.permute(1, 0, 2)\n","\n","        residual_sum = self.user_layer_norm(user_hiddens + seqs)\n","        user_title_hidden = news_self_attend(residual_sum)\n","\n","        return user_title_hidden\n","\n","\n","class NodesEncoder(nn.Module):\n","    def __init__(self, cfg):\n","        super(NodesEncoder, self).__init__()\n","        self.cfg = cfg\n","        \n","        self.user_mh_self_attn = nn.MultiheadAttention(\n","            cfg.hidden_size, num_heads=cfg.head_num)\n","        \n","        self.nodes_mh_self_attn = nn.MultiheadAttention(\n","            cfg.hidden_size, num_heads=cfg.head_num)\n","        \n","        self.pos_self_attend = SelfAttend(cfg.hidden_size)\n","\n","        self.dropout = nn.Dropout(cfg.dropout)\n","        self.user_layer_norm = nn.LayerNorm(cfg.hidden_size)\n","\n","    def forward(self, pos): ## neg, pos_nodes, neg_nodes\n","        \"\"\"\n","        Args:\n","            seqs: [*, max_hist_len, hidden_size]\n","        Returns:\n","            [*, hidden_size]\n","        \"\"\"\n","\n","        pos_permuted = pos.permute(1, 0, 2)\n","        pos_hiddens, _ = self.user_mh_self_attn(pos_permuted, pos_permuted, pos_permuted)\n","        pos_hiddens = pos_hiddens.permute(1, 0, 2)\n","        pos_residual = self.user_layer_norm(pos_hiddens + pos)\n","\n","        pos_s = self.pos_self_attend(pos_residual)\n","\n","\n","        return pos_s ## pos_s, pos_s_nodes, neg_s, neg_s_nodes, pos_c, pos_c_nodes, neg_c, neg_c_nodes\n","\n","class MaskedSelfAttend(nn.Module):\n","    def __init__(self, hidden_size, mask_len) -> None:\n","        super(MaskedSelfAttend, self).__init__()\n","\n","        # self.query = nn.Linear(cfg.hidden_size, cfg.hidden_size)\n","        # self.key = nn.Linear(cfg.hidden_size, cfg.hidden_size)\n","        # self.value = nn.Linear(cfg.hidden_size, cfg.hidden_size)\n","        self.mask = nn.Parameter(torch.eye(mask_len) == 1, requires_grad=False)\n","        self.hidden_size = hidden_size\n","\n","    def forward(self, q):\n","        # q (batch_size, seq_len, hidden_size)\n","        \n","        k = q.permute(0, 2, 1)\n","        sim = torch.matmul(q, k) / math.sqrt(self.hidden_size)\n","        sim = torch.softmax(sim.masked_fill_(self.mask, -1e9), dim=-1)\n","        output = torch.matmul(sim, q)\n","\n","        return output\n","\n","class Multihead_bandti(nn.Module):\n","\n","    def __init__(self, cfg):\n","\n","        super(Multihead_bandti, self).__init__()\n","\n","        self.head_num = cfg.head_num\n","        self.head_dim = cfg.hidden_size // cfg.head_num\n","        self.hidden_size = cfg.hidden_size\n","        \n","        self.policy_1 = nn.Sequential(\n","            nn.Linear(cfg.hidden_size * 2, cfg.hidden_size),\n","            nn.Tanh(),\n","            nn.Linear(cfg.hidden_size, self.head_num))\n","\n","    \n","    def forward(self, refer, s1, s2, s3, s4):\n","\n","        gamma_1 = self.policy_1(refer).unsqueeze(-1)\n","\n","        s1 = s1.view(-1, refer.size(1), self.head_num, self.head_dim)\n","        final = gamma_1 * s1\n","        final = final.reshape(-1, refer.size(1), self.hidden_size)\n","\n","        return final"],"metadata":{"id":"-9cbqoYok0fT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# `pnrec`"],"metadata":{"id":"squ2WAfblnv9"}},{"cell_type":"code","source":["import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class PNRec(nn.Module):\n","    def __init__(self, cfg):\n","        super(PNRec, self).__init__()\n","\n","        self.title_encoder = TitleEncoder(cfg)\n","        self.news_encoder = NodesEncoder(cfg)\n","        self.cfg = cfg\n","        self.policy_pos_s = nn.Sequential(\n","            nn.Linear(cfg.hidden_size * 2, cfg.hidden_size),\n","            nn.Tanh(),\n","            nn.Linear(cfg.hidden_size, 1),)\n"," \n","\n","        self.news_embedding = nn.Embedding(cfg.tracks_num, cfg.hidden_size)\n","\n","        self.title_self_attend = SelfAttend(cfg.hidden_size)\n","\n","    def forward(self, data, test_mode=False):\n","        neg_num = self.cfg.neg_count\n","        if test_mode:\n","            neg_num = 0\n","\n","        target_news = data[3].reshape(-1, self.cfg.max_lyric_len)\n","        target_news = self.title_encoder.encode_news(target_news).reshape(-1, neg_num + 1, self.cfg.hidden_size)\n","        target_all = target_news\n","\n","        pos_his = data[4].reshape(-1, self.cfg.max_lyric_len)\n","        pos_his = self.title_encoder.encode_news(pos_his).reshape(-1, self.cfg.pos_hist_length, self.cfg.hidden_size)\n","\n","        title_v = self.title_self_attend(pos_his)\n","        title_v = title_v.repeat(1, neg_num + 1).view(-1, neg_num + 1, self.cfg.hidden_size)\n","        \n","        pos_s= self.news_encoder(pos_his)\n","\n","        pos_s = pos_s.repeat(1, neg_num + 1).view(-1, neg_num + 1, self.cfg.hidden_size)\n","     \n","        news_states = torch.cat([title_v, target_news], dim=-1)\n","        gamma_1 = self.policy_pos_s(news_states)\n","        news_final = gamma_1 * pos_s\n","\n","        ###return torch.sum(torch.cat([news_final, node_final], dim=-1) * target_all, dim=-1)\n","        return torch.sum(news_final * target_all, dim=-1)"],"metadata":{"id":"tIsWDpL_lvGD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# `validate`"],"metadata":{"id":"3DS61EpZECVy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"97z4PX79Xlb9"},"outputs":[],"source":["import os\n","import argparse\n","import json\n","import pickle\n","from tqdm import tqdm\n","import time\n","import torch\n","import numpy as np\n","import torch.distributed as dist\n","import torch.nn.functional as F\n","import logging\n","from torch.utils.data import Dataset, TensorDataset, DataLoader\n","import math\n","\n","\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n","\n","def run(dev_dataset, epoch):\n","    filenum=20\n","    batch_size=128\n","    root=\"data\"\n","    start_dev=2\n","    result_path = 'result/test/'\n","    saved_model_path = 'checkpoint/model.ep{}'.format(epoch)\n","\n","    model_cfg = ModelConfig(root)\n","    model = PNRec(model_cfg)\n","\n","    pretrained_model = torch.load(saved_model_path)\n","\n","    model.load_state_dict(pretrained_model['model_state_dict'], strict=False)\n","    model.eval()\n","    \n","    valid_data_loader = DataLoader(dev_dataset, shuffle=False)\n","\n","    data_iter = tqdm(enumerate(valid_data_loader),\n","                        desc=\"epoch_dev %d\" % epoch,\n","                        total=len(valid_data_loader),\n","                        bar_format=\"{l_bar}{r_bar}\")\n","\n","    with torch.no_grad():\n","        preds, truths, imp_ids = list(), list(), list()\n","        for i, data in data_iter:\n","\n","            imp_ids += data[0].numpy().tolist()\n","            truths += data[1].numpy().tolist()\n","\n","            pred = model(data, test_mode=True)\n","            if pred.dim() > 1:\n","                pred = pred.squeeze()\n","            try:\n","                preds += pred.numpy().tolist()\n","            except:\n","                preds.append(int(pred.numpy()))\n","\n","        tmp_dict = {}\n","        tmp_dict['imp'] = imp_ids\n","        tmp_dict['labels'] = truths\n","        tmp_dict['preds'] = preds\n","\n","        with open(result_path + 'tmp_test-{}.json'.format(epoch), 'w+', encoding='utf-8') as f:\n","            json.dump(tmp_dict, f)\n","\n","    gather(result_path, 'tmp_test-{}.json'.format(epoch), epoch, validate=True, save=True)\n"]},{"cell_type":"markdown","source":["# ***RUN***"],"metadata":{"id":"_xKKOs8nteju"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"yZX7zY0Rtq9N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671430714078,"user_tz":-420,"elapsed":25250,"user":{"displayName":"Oanh Phan","userId":"17182359449857038957"}},"outputId":"fee6e3b2-4e54-4309-a797-366a5bc5bd1f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd '/content/drive/MyDrive/Những năm tháng Đại học/[4] DS300.N11 - Hệ khuyến nghị/ReSys_/DRPN'"],"metadata":{"id":"MHn5UlHctxFv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671430715047,"user_tz":-420,"elapsed":982,"user":{"displayName":"Oanh Phan","userId":"17182359449857038957"}},"outputId":"0323219b-c0c6-4b1b-f668-4a5b136e48b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/127eMhUqzE2w-Fg1IDb9eLKYQHPsZSeG2/Những năm tháng Đại học/[4] DS300.N11 - Hệ khuyến nghị/ReSys_/DRPN\n"]}]},{"cell_type":"code","source":["test = torch.load('data/test/test.pt')\n","for i in range(5):\n","  save_model_path = 'checkpoint/model.ep{}'.format(i)\n","  run(test, i)\n","  "],"metadata":{"id":"d9QsHUAQtg7U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671436769409,"user_tz":-420,"elapsed":6038147,"user":{"displayName":"Oanh Phan","userId":"17182359449857038957"}},"outputId":"acbaca93-5375-4be0-8e6f-105e42784d91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["epoch_dev 0: 100%|| 13477/13477 [19:59<00:00, 11.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval - group_auc: 0.8899\n","Eval - mean_mrr: 0.2227\n","Eval - ndcg@5: 0.9068\n","Eval - ndcg@10: 0.9015\n"]},{"output_type":"stream","name":"stderr","text":["epoch_dev 1: 100%|| 13477/13477 [20:03<00:00, 11.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval - group_auc: 0.9187\n","Eval - mean_mrr: 0.2312\n","Eval - ndcg@5: 0.9431\n","Eval - ndcg@10: 0.934\n"]},{"output_type":"stream","name":"stderr","text":["epoch_dev 2: 100%|| 13477/13477 [20:00<00:00, 11.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval - group_auc: 0.9313\n","Eval - mean_mrr: 0.2336\n","Eval - ndcg@5: 0.9475\n","Eval - ndcg@10: 0.9436\n"]},{"output_type":"stream","name":"stderr","text":["epoch_dev 3: 100%|| 13477/13477 [20:12<00:00, 11.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval - group_auc: 0.9334\n","Eval - mean_mrr: 0.234\n","Eval - ndcg@5: 0.9489\n","Eval - ndcg@10: 0.9432\n"]},{"output_type":"stream","name":"stderr","text":["epoch_dev 4: 100%|| 13477/13477 [20:03<00:00, 11.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Eval - group_auc: 0.9381\n","Eval - mean_mrr: 0.237\n","Eval - ndcg@5: 0.9579\n","Eval - ndcg@10: 0.9521\n"]}]},{"cell_type":"code","source":["save_model_path = 'checkpoint/model.ep{}'.format(1)\n","run(test, i)"],"metadata":{"id":"i1R_EHWj8gXY"},"execution_count":null,"outputs":[]}]}